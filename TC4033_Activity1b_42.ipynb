{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarmentamna/machine_learning_advance/blob/main/TC4033_Activity1b_42.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Maestría en Inteligencia Artificial Aplicada**\n",
        "###**Curso: ADVANCE MACHINE LEARNING METHODS**\n",
        "## Tecnológico de Monterrey\n",
        "###Dr. José Antonio Cantoral Ceballos\n",
        "\n",
        "## Activity Week 2\n",
        "###**Implementing a Fully Connected Network for Kaggle ASL Dataset.**\n",
        "\n",
        "*TEAM MEMBERS:*\n",
        "\n",
        "*   Roberto Romero Vielma - A00822314\n",
        "*   José Javier Granados Hernández - A00556717\n",
        "*   Aquiles Yonatan Armenta Hernandez - A01793252\n",
        "*   Alan Avelino Fernández Juárez - A00989308"
      ],
      "metadata": {
        "id": "Cnc-mfautnHW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNufdnTdq_ug"
      },
      "source": [
        "# TC 5033\n",
        "## Deep Learning\n",
        "## Fully Connected Deep Neural Networks\n",
        "\n",
        "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
        "\n",
        "- Objective\n",
        "\n",
        "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
        "\n",
        "- Instructions\n",
        "\n",
        "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
        "\n",
        "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
        "\n",
        "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
        "\n",
        "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
        "\n",
        "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
        "    \n",
        "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
        "\n",
        "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
        "\n",
        "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
        "\n",
        "- Evaluation Criteria\n",
        "\n",
        "    - Code Readability and Comments\n",
        "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
        "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
        "    - Quality of Markdown documentation\n",
        "\n",
        "- Submission\n",
        "\n",
        "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library imports and data download"
      ],
      "metadata": {
        "id": "vpT5CVE7Edoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Clone Repository:\n",
        "\n",
        "  - The code starts by cloning a GitHub repository containing sign language data using !git clone.\n",
        "2. Import Libraries:\n",
        "\n",
        "  - Various libraries are imported, including NumPy, string, Pandas, Matplotlib, OpenCV, and OS. These libraries are used for data manipulation, visualization, and computer vision.\n",
        "3. Configure Jupyter Notebook:\n",
        "\n",
        "  - %load_ext autoreload and %autoreload 2 configure the Jupyter Notebook to automatically reload modified modules.\n",
        "  %matplotlib inline ensures that Matplotlib plots are displayed inline.\n",
        "4. Define Data Path:\n",
        "\n",
        "  - DATA_PATH is defined as the path to the data directory './asl_data/'.\n",
        "5. Read Data:\n",
        "\n",
        "  - Training and validation data are read from CSV files into Pandas DataFrames: train_df and valid_df.\n",
        "6. Data Reshaping:\n",
        "\n",
        "  - The image data in both DataFrames is extracted and reshaped from a flat 784-vector format into 28x28 matrices for training and validation sets (x_train_num and x_test_num).\n",
        "7. Label Extraction:\n",
        "\n",
        "  - Labels for training and validation data are extracted and stored in y_train_num and y_test_num.\n",
        "8. Check Data Shapes:\n",
        "\n",
        "  - The shapes of the reshaped data arrays and the validation DataFrame are checked."
      ],
      "metadata": {
        "id": "-81yi76MEdeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository from the following URL\n",
        "!git clone https://github.com/rromerov/asl_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhKnET9JrUH0",
        "outputId": "ed920275-563e-4eed-8dbc-313fe91e9269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'asl_data'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4/4), 29.39 MiB | 12.74 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg_aW5deq_uk"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np          # Import NumPy for numerical operations\n",
        "import string               # Import the string module for working with strings\n",
        "import pandas as pd         # Import Pandas for data manipulation\n",
        "import matplotlib.pyplot as plt  # Import Matplotlib for data visualization\n",
        "import cv2 as cv            # Import OpenCV for computer vision tasks\n",
        "import os                   # Import the os module for interacting with the operating system\n",
        "\n",
        "# Load the autoreload extension to automatically reload modified modules\n",
        "%load_ext autoreload\n",
        "\n",
        "# Set autoreload to reload all modules every time a cell is executed\n",
        "%autoreload 2\n",
        "\n",
        "# Use %matplotlib inline to display Matplotlib plots inline in the Jupyter Notebook\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLUsI4uKq_um"
      },
      "outputs": [],
      "source": [
        "# Declare the path to the directory containing the data from GitHub repository\n",
        "DATA_PATH = './asl_data/'\n",
        "\n",
        "# Read the training data from a CSV file located in the DATA_PATH directory\n",
        "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
        "\n",
        "# Read the validation data from a CSV file located in the DATA_PATH directory\n",
        "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "WdgOYB2Iq_um",
        "outputId": "da86feb6-13cb-49ff-f9a3-cf57dc47da88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3     107     118     127     134     139     143     146     150   \n",
              "1      6     155     157     156     156     156     157     156     158   \n",
              "2      2     187     188     188     187     187     186     187     188   \n",
              "3      2     211     211     212     212     211     210     211     210   \n",
              "4     12     164     167     170     172     176     179     180     184   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0     153  ...       207       207       207       207       206       206   \n",
              "1     158  ...        69       149       128        87        94       163   \n",
              "2     187  ...       202       201       200       199       198       199   \n",
              "3     210  ...       235       234       233       231       230       226   \n",
              "4     185  ...        92       105       105       108       133       163   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       206       204       203       202  \n",
              "1       175       103       135       149  \n",
              "2       198       195       194       195  \n",
              "3       225       222       229       163  \n",
              "4       157       163       164       179  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3de8a35b-314e-481f-9652-ccd9df892c7e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3de8a35b-314e-481f-9652-ccd9df892c7e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3de8a35b-314e-481f-9652-ccd9df892c7e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3de8a35b-314e-481f-9652-ccd9df892c7e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52c7feb0-0d08-4b7b-94e7-cd61a662a514\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52c7feb0-0d08-4b7b-94e7-cd61a662a514')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52c7feb0-0d08-4b7b-94e7-cd61a662a514 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Display the first few rows (header) of the extracted training data\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGk44QCkq_um",
        "outputId": "da9a4005-8449-4245-cf49-beb8c0fa55d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Obtain and sort unique categories (labels)\n",
        "np.unique(train_df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpYHPR8jq_um",
        "outputId": "b3c9222c-e299-44d8-fd95-1ce5aa796ec0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Extract and reshape the 784-vector data into a 28x28 matrix for the training set\n",
        "x_train_num = train_df.loc[:, train_df.columns != 'label'].values.copy().reshape(-1, 28, 28)\n",
        "\n",
        "# Check the shape of the reshaped training data\n",
        "x_train_num.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP5Cazb5q_un",
        "outputId": "f5aba538-e297-4750-cdd1-a9e0f6c568cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Extract the label values for the training set\n",
        "y_train_num = train_df['label'].values.copy()\n",
        "\n",
        "# Check the shape of the extracted label values\n",
        "y_train_num.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx5S-NOsq_un",
        "outputId": "f2074e13-320b-4bf5-8efc-275a9778201d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Extract and reshape images from vectors to 28x28 matrices for the validation set\n",
        "x_test_num = valid_df.loc[:, valid_df.columns != 'label'].values.copy().reshape(-1, 28, 28)\n",
        "\n",
        "# Check the shape of the reshaped validation data\n",
        "x_test_num.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX4BZAccq_un",
        "outputId": "2be4590e-08e6-4301-fec3-b311ba8d27bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Extract the label values for the validation set\n",
        "y_test_num = valid_df['label'].values.copy()\n",
        "\n",
        "# Check the shape of the extracted label values for the validation set\n",
        "y_test_num.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op_0kiBKq_un",
        "outputId": "fec95692-ab50-4611-8a99-f3ae2071fd8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Check the shape of the validation DataFrame (valid_df)\n",
        "valid_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1Wd_Udjq_un"
      },
      "outputs": [],
      "source": [
        "# Cast data type to NumPy arrays\n",
        "y_train = np.array(train_df['label'])   # Convert the 'label' column of the training DataFrame to a NumPy array\n",
        "y_val = np.array(valid_df['label'])     # Convert the 'label' column of the validation DataFrame to a NumPy array\n",
        "\n",
        "# Delete the original 'label' data in the DataFrames to keep only the feature data\n",
        "del train_df['label']    # Delete the 'label' column from the training DataFrame\n",
        "del valid_df['label']    # Delete the 'label' column from the validation DataFrame\n",
        "\n",
        "# Change data type for matrices to float32\n",
        "x_train = train_df.values.astype(np.float32)  # Convert the training DataFrame to a NumPy array with float32 data type\n",
        "x_val = valid_df.values.astype(np.float32)    # Convert the validation DataFrame to a NumPy array with float32 data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gAXE2yrq_un",
        "outputId": "4c9f6416-752e-4de0-9a00-3f4ae2ed4f81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Check the shape of the training feature data (x_train)\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbqLJ6Bgq_uo",
        "outputId": "980b84e6-de3f-49de-e842-84acecbc216b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Check the shape of the training feature data (y_train)\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pELGq4CGq_uo",
        "outputId": "75ade2a2-f98e-420e-daa7-ebab846065c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Transpose the label vector\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "# Check the shape of the transposed label vector\n",
        "y_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skHKQi2uq_uo",
        "outputId": "7cf0a8fe-edc3-4729-b10e-c8669c3865dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Transpose the validation label vector\n",
        "y_val = y_val.reshape(-1, 1)\n",
        "\n",
        "# Check the shape of the transposed validation label vector\n",
        "y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to Split a Dataset into Validation and Test Sets\n",
        "\n",
        "This function called `split_val_test` is used to split a dataset into two parts: a validation set and a test set. Below is a step-by-step description of the code:\n",
        "\n",
        "1. Checking the length of input data and labels:\n",
        "   - The function begins by checking whether the length of the input data `x` is equal to the length of the labels `y`. This is essential because data and labels must match in length.\n",
        "\n",
        "2. Calculating the number of test samples:\n",
        "   - Next, the number of test samples (`num_test_samples`) is calculated based on the specified percentage (`pct`) and the length of the input data (`x`). This number is computed as an integer from the multiplication of the length of `x` by `pct`. By default, `pct` is set to 0.5, meaning that, by default, the dataset will be divided equally into validation and test parts.\n",
        "\n",
        "3. Creating an array of indices:\n",
        "   - The function creates an array of indices using the `np.arange` function based on the length of the input data. These indices will be used to split the data into validation and test sets.\n",
        "\n",
        "4. Shuffling the indices (optional):\n",
        "   - If the `shuffle` flag is set to `True`, the function shuffles the indices using `np.random.shuffle`. This ensures that samples are randomly selected for the validation and test sets.\n",
        "\n",
        "5. Separating the indices into validation and test sets:\n",
        "   - The indices are split into two sets: `val_indices` and `test_indices`. `val_indices` contains the indices of samples that will be used as the validation set, and `test_indices` contains the indices of samples that will be used as the test set.\n",
        "\n",
        "6. Assigning data and labels to the validation and test sets:\n",
        "   - Finally, the corresponding data and labels are assigned to the validation (`x_val` and `y_val`) and test (`x_test` and `y_test`) sets using the indices obtained in the previous step.\n",
        "\n",
        "7. Returning the validation and test sets:\n",
        "   - The function returns the four resulting sets: `x_val`, `y_val`, `x_test`, and `y_test`.\n",
        "\n",
        "This function is useful for splitting a dataset into two parts for validation and performance testing in machine learning models. You can adjust the split percentage and control whether random shuffling of the data is performed according to your needs.\n"
      ],
      "metadata": {
        "id": "xF0fTmpV1gEl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvQl0_M_q_uo"
      },
      "outputs": [],
      "source": [
        "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
        "    '''\n",
        "    A function to split a previously loaded validation set into validation and test sets.\n",
        "    '''\n",
        "    # Check if the lengths of input data and labels are the same\n",
        "    if len(x) != len(y):\n",
        "        raise ValueError(\"Input data and labels must have the same length.\")\n",
        "\n",
        "   # Calculate the number of test samples based on the input percentage\n",
        "    num_test_samples = int(len(x) * pct)\n",
        "\n",
        "    # Create an array of indices based on the length of the input data\n",
        "    indices = np.arange(len(x))\n",
        "\n",
        "    # Shuffle the indices if the shuffle flag is set to True\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "     # Slice the shuffled indices to separate validation and test samples\n",
        "    val_indices = indices[num_test_samples:]\n",
        "    test_indices = indices[:num_test_samples]\n",
        "\n",
        "   # Assign the appropriate indices to create validation and test sets\n",
        "    x_val, y_val = x[val_indices], y[val_indices]\n",
        "    x_test, y_test = x[test_indices], y[test_indices]\n",
        "\n",
        "    return x_val, y_val, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qELz3A0Yq_uo"
      },
      "outputs": [],
      "source": [
        "# Generate validation and test data sets by calling the split_val_test function\n",
        "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94PwbB5pq_uo",
        "outputId": "2ae030eb-4b4e-49cc-8dc1-9a076bc3fb22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3586, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Check the shape of the validation feature data (x_val)\n",
        "x_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLRypPZ9q_uo",
        "outputId": "59070406-71a1-4474-b8b9-c1e8a408a32e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3586, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Check the shape of the validation feature data (y_val)\n",
        "y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBXp-oLXq_uo",
        "outputId": "a1ad639b-829c-476b-fe53-a170c4095847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "# Modify the set of alphabet characters to exclude 'j' and 'z'\n",
        "alphabet = list(string.ascii_lowercase)   # Create a list containing all lowercase letters\n",
        "alphabet.remove('j')                      # Remove the letter 'j' from the list\n",
        "alphabet.remove('z')                      # Remove the letter 'z' from the list\n",
        "\n",
        "print(len(alphabet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgRoQu5gq_uo"
      },
      "source": [
        "### Normalise\n",
        "#### Normalization Function\n",
        "\n",
        "This function named `normalize` is designed for performing data normalization. Data normalization is a preprocessing technique commonly used in machine learning to scale input data to have a consistent scale and zero mean. Below is a step-by-step description of the code:\n",
        "\n",
        "1. Function Parameters:\n",
        "   - The function accepts three parameters:\n",
        "     - `x_mean`: Mean value for normalization.\n",
        "     - `x_std`: Standard deviation value for normalization.\n",
        "     - `x_data`: Input data to be normalized.\n",
        "\n",
        "2. Normalization Formula:\n",
        "   - Inside the function, data normalization is performed using the formula:\n",
        "\n",
        "$$\\frac{x_{\\text{data}} - x_{\\text{mean}}}{x_{\\text{std}}}$$\n",
        "\n",
        "  This formula subtracts the mean (`x_mean`) from each data point in `x_data` and then divides the result by the standard deviation (`x_std`). This process scales the data so that it has a mean of zero and a standard deviation of one.\n",
        "\n",
        "3. Return Value:\n",
        "   - The normalized data is returned as the result of the function.\n",
        "\n",
        "4. Purpose of Normalization:\n",
        "   - Data normalization is a crucial preprocessing step in many machine learning algorithms. It ensures that features with different scales do not dominate the learning process and helps improve the stability and convergence of machine learning models.\n",
        "\n",
        "5. Example Usage:\n",
        "   - To use this function, you would provide the mean and standard deviation values you want to use for normalization (`x_mean` and `x_std`) along with the input data (`x_data`). The function will then return the normalized data.\n",
        "\n",
        "   Example:\n",
        "   #### Calculate mean and standard deviation for normalization\n",
        "   x_mean = np.mean(training_data)\n",
        "   x_std = np.std(training_data)\n",
        "\n",
        "   #### Normalize the data\n",
        "   normalized_data = normalize(x_mean, x_std, training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7lMbLbTq_uo"
      },
      "outputs": [],
      "source": [
        "# Normalization function\n",
        "def normalize(x_mean, x_std, x_data):\n",
        "    '''\n",
        "    This function performs normalization on input data.\n",
        "\n",
        "    Parameters:\n",
        "    - x_mean: Mean value for normalization.\n",
        "    - x_std: Standard deviation value for normalization.\n",
        "    - x_data: Input data to be normalized.\n",
        "\n",
        "    Returns:\n",
        "    - Normalized data.\n",
        "    '''\n",
        "    return (x_data - x_mean) / x_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4kYLDXuq_uo"
      },
      "outputs": [],
      "source": [
        "# Normalization of all data sets using previously calculated mean and standard deviation\n",
        "x_mean = x_train.mean()          # Calculate the mean of the training data\n",
        "x_std = x_train.std()            # Calculate the standard deviation of the training data\n",
        "\n",
        "x_train = normalize(x_mean, x_std, x_train)  # Normalize the training data\n",
        "x_val = normalize(x_mean, x_std, x_val)      # Normalize the validation data\n",
        "x_test = normalize(x_mean, x_std, x_test)    # Normalize the test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpYYAv5Sq_uo",
        "outputId": "a1e99b16-a84c-4552-92f8-0b4aec8f43d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.6268384e-06, 0.99999946)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Calculate the mean and standard deviation of the values in x_train\n",
        "x_train.mean(), x_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMwMLXVeq_uo"
      },
      "source": [
        "### Graficar muestras\n",
        "#### Plotting Function\n",
        "\n",
        "This function named `plot_number` is used for plotting grayscale images. It's a simple utility function for displaying images using the Matplotlib library in Python. Below is a step-by-step explanation of the code:\n",
        "\n",
        "1. Function Parameter:\n",
        "   - The function takes one parameter, `image`, which is expected to be a grayscale image to be plotted.\n",
        "\n",
        "2. Creating a Figure for Plotting:\n",
        "   - Inside the function, a new figure for plotting is created using `plt.figure(figsize=(5,5))`. This specifies the size of the figure as 5x5 inches.\n",
        "\n",
        "3. Displaying the Grayscale Image:\n",
        "   - The grayscale image is displayed using `plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))`.\n",
        "     - `plt.imshow()` is a function from Matplotlib used for displaying images.\n",
        "     - `image.squeeze()` is used to remove any single-dimensional entries from the shape of the `image`. This is typically used to ensure that the image has the right dimensions for display.\n",
        "     - `cmap=plt.get_cmap('gray')` specifies that the colormap used for displaying the image is grayscale.\n",
        "\n",
        "4. Turning Off Axis Labels:\n",
        "   - `plt.axis('off')` is used to turn off the axis labels, ensuring that no x or y-axis ticks and labels are displayed on the plot.\n",
        "\n",
        "5. Displaying the Plot:\n",
        "   - `plt.show()` is used to display the plot on the screen.\n",
        "\n",
        "6. Purpose of the Function:\n",
        "   - This function is useful when working with image data in Python. It provides a convenient way to visualize grayscale images during data exploration, analysis, or model development.\n",
        "\n",
        "7. Example Usage:\n",
        "   - To use this function, you would simply pass a grayscale image as the `image` parameter, and it will display the image in a Matplotlib plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q-uo8MMq_uo"
      },
      "outputs": [],
      "source": [
        "# Plotting function\n",
        "def plot_number(image):\n",
        "    '''\n",
        "    This function plots a grayscale image.\n",
        "\n",
        "    Parameters:\n",
        "    - image: The grayscale image to be plotted.\n",
        "    '''\n",
        "    plt.figure(figsize=(5,5))                # Create a figure for plotting\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))  # Display the image with a grayscale colormap\n",
        "    plt.axis('off')                          # Turn off the axis labels\n",
        "    plt.show()                               # Display the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "MHcVgfIdq_uo",
        "outputId": "d7b6fdfa-9696-4a75-8616-65f1b97499f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sampled image represents: e\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Sample plot\n",
        "rnd_idx = np.random.randint(len(y_test))  # Generate a random index within the range of the test data\n",
        "print(f'The sampled image represents: {alphabet[int(y_test[rnd_idx])]}') # Print a message indicating what the sampled image represents based on the label (alphabet) of the random test data point\n",
        "plot_number(x_test_num[rnd_idx]) # Call the function plot_number() to display the image corresponding to the randomly selected test data point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzqbgj2yq_uo"
      },
      "source": [
        "### Ecuaciones para nuestro modelo\n",
        "\n",
        "\n",
        "$$z^1 = W^1 X + b^1$$\n",
        "\n",
        "$$a^1 = ReLU(z^1) $$\n",
        "\n",
        "$$z^2 = W^2 a^1 + b^2$$\n",
        "\n",
        "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYdfZ10hq_uo"
      },
      "source": [
        "### Funciones adicionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j-0ifP8q_up"
      },
      "source": [
        "#### Mini batches\n",
        "#### Minibatch Generator or Data Sampler\n",
        "\n",
        "This function named `create_minibatches` is used for generating minibatches or samples from input data. Minibatches are commonly used in machine learning for training models in smaller, manageable chunks. Below is a step-by-step explanation of the code:\n",
        "\n",
        "1. Function Parameters:\n",
        "   - The function takes four parameters:\n",
        "     - `mb_size`: Mini-batch size, which determines the number of samples in each minibatch.\n",
        "     - `x`: Input feature data.\n",
        "     - `y`: Corresponding labels.\n",
        "     - `shuffle`: A boolean flag to indicate whether to shuffle the data before sampling minibatches.\n",
        "\n",
        "2. Consistency Check:\n",
        "   - The function begins by checking if the number of samples in the input feature data `x` matches the number of samples in the corresponding labels `y`. This ensures that the data and labels have the same number of samples.\n",
        "\n",
        "3. Total Data Count:\n",
        "   - It calculates the total number of samples in the dataset, which is the length of the first dimension of the input feature data `x`.\n",
        "\n",
        "4. Data Shuffling:\n",
        "   - If the `shuffle` flag is set to `True`, the function performs data shuffling to randomize the order of samples. This is useful for avoiding any sequence-related bias in the dataset. Shuffling is achieved by:\n",
        "     - Creating an array of indices from 0 to `total_data-1`.\n",
        "     - Randomly shuffling these indices using `np.random.shuffle`.\n",
        "     - Rearranging the feature data `x` and labels `y` based on the shuffled indices, ensuring that data and labels remain aligned.\n",
        "\n",
        "5. Mini-batch Generator:\n",
        "   - The function then creates and returns a generator that yields minibatches of data. It does this using a generator expression:\n",
        "     - `((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))`\n",
        "     - This generator iterates over the data in chunks of `mb_size`, creating minibatches of feature data and labels. The `i` variable determines the starting index for each minibatch.\n",
        "\n",
        "6. Purpose of the Function:\n",
        "   - This function is valuable for training machine learning models, especially deep learning models, using minibatch gradient descent. It allows you to efficiently process large datasets in smaller chunks, reducing memory requirements and potentially speeding up training.\n",
        "\n",
        "7. Example Usage:\n",
        "   - To use this function, you would provide the mini-batch size (`mb_size`), input feature data (`x`), and corresponding labels (`y`). You can also specify whether to shuffle the data (`shuffle` parameter)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfMojYpnq_up"
      },
      "outputs": [],
      "source": [
        "# Minibatch generator or Data sampler\n",
        "def create_minibatches(mb_size, x, y, shuffle=True):\n",
        "    '''\n",
        "    This function generates minibatches or samples from input data.\n",
        "\n",
        "    Parameters:\n",
        "    - mb_size: Mini-batch size, determining the number of samples in each minibatch.\n",
        "    - x: Input feature data.\n",
        "    - y: Corresponding labels.\n",
        "    - shuffle: Boolean flag to shuffle the data before sampling.\n",
        "\n",
        "    Returns:\n",
        "    - Generator for minibatches, each containing a mini-batch of feature data and labels.\n",
        "    '''\n",
        "    # Ensure that the input data has consistent shape\n",
        "    assert x.shape[0] == y.shape[0], 'Error: Inconsistent number of samples'\n",
        "    total_data = x.shape[0]\n",
        "\n",
        "    # Shuffle the data if the shuffle flag is set to True\n",
        "    # If the 'shuffle' flag is True, we will randomly reorder the data.\n",
        "\n",
        "    if shuffle:\n",
        "        # Create an array of indices from 0 to (total_data-1)\n",
        "        idxs = np.arange(total_data)\n",
        "\n",
        "        # Shuffle the indices randomly\n",
        "        np.random.shuffle(idxs)\n",
        "\n",
        "        # Rearrange the feature data 'x' and labels 'y' based on the shuffled indices\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]\n",
        "\n",
        "    # Create and return a generator that yields minibatches of data\n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX4OpVn-q_up"
      },
      "source": [
        "## Nuestra clase Linear, ReLU y Sequential\n",
        "#### Custom NumPy Array Subclass: `np_tensor`\n",
        "\n",
        "The following code defines a custom NumPy array subclass called `np_tensor`. This subclass inherits from the `np.ndarray` class, which is the fundamental array data structure in the NumPy library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9yelREUq_up"
      },
      "outputs": [],
      "source": [
        "# Custom class np_tensor to inherit from np.ndarray\n",
        "class np_tensor(np.ndarray): pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOEsrpmvq_up"
      },
      "source": [
        "###  Clase Linear\n",
        "#### Class for Linear Transformation with Evaluation Function for Input and Weights\n",
        "\n",
        "The code defines a Python class called `Linear` that represents a linear transformation layer. This class is typically used in neural networks and deep learning models. Below is a step-by-step explanation of the code:\n",
        "\n",
        "##### `__init__` Method:\n",
        "- The `__init__` method is the constructor of the class, which initializes the layer's parameters.\n",
        "- It takes two arguments: `input_size` and `output_size`, representing the dimensions of the input and output of the linear layer.\n",
        "- Inside the constructor:\n",
        "  - The weight matrix 'W' is initialized using Kaiming He initialization. This is done to help stabilize the training of neural networks. The weights are sampled from a Gaussian distribution with a mean of 0 and a standard deviation of `np.sqrt(input_size/2)`. The `view(np_tensor)` at the end of this line suggests that the resulting NumPy array should be treated as an instance of a custom NumPy array subclass called `np_tensor`.\n",
        "  - The bias vector 'b' is initialized with zeros. It has a shape of `(output_size, 1)` and is also treated as an instance of `np_tensor`.\n",
        "\n",
        "##### `__call__` Method:\n",
        "- The `__call__` method defines the forward pass of the linear transformation.\n",
        "- It takes an input tensor `X` as an argument.\n",
        "- Inside the method:\n",
        "  - It computes the linear transformation by performing matrix multiplication between the weight matrix 'W' and the input 'X', and then adding the bias vector 'b'.\n",
        "  - The result of this computation is returned as the output of the layer.\n",
        "\n",
        "##### `backward` Method:\n",
        "- The `backward` method defines the backward pass, which computes gradients during backpropagation.\n",
        "- It takes two arguments: `X` (the input) and `Z` (the output of the forward pass).\n",
        "- Inside the method:\n",
        "  - It computes the gradient of the input 'X' by performing matrix multiplication between the transpose of the weight matrix 'W' and the gradient of the output 'Z'. This gradient is stored in the 'grad' attribute of 'X'.\n",
        "  - It computes the gradient of the weight matrix 'W' by performing matrix multiplication between the gradient of the output 'Z' and the transpose of the input 'X'. This gradient is stored in the 'grad' attribute of 'W'.\n",
        "  - It computes the gradient of the bias vector 'b' by summing the gradient of the output 'Z' along the appropriate axis and keeping the dimensions consistent. This gradient is stored in the 'grad' attribute of 'b'.\n",
        "\n",
        "This `Linear` class is a fundamental building block in neural networks, and it can be used as a layer to perform linear transformations followed by non-linear activation functions in deep learning models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2ldqrm7q_up"
      },
      "outputs": [],
      "source": [
        "# Class for linear transformation with evaluation function for input and weights\n",
        "class Linear():\n",
        "    def __init__(self, input_size, output_size):\n",
        "        '''\n",
        "        Initialize parameters using Kaiming He initialization.\n",
        "        '''\n",
        "        # Initialize the weight matrix 'W' with Kaiming He initialization\n",
        "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
        "        # Initialize the bias vector 'b' with zeros\n",
        "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
        "    def __call__(self, X):\n",
        "        # Forward pass: Compute the linear transformation\n",
        "        Z = self.W @ X + self.b\n",
        "        return Z\n",
        "    def backward(self, X, Z):\n",
        "        # Backward pass: Compute gradients\n",
        "        # Compute the gradient of the input 'X'\n",
        "        X.grad = self.W.T @ Z.grad\n",
        "        # Compute the gradient of the weight matrix 'W'\n",
        "        self.W.grad = Z.grad @ X.T\n",
        "        # Compute the gradient of the bias vector 'b'\n",
        "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmjAwBvuq_up"
      },
      "source": [
        "### Clase ReLU\n",
        "#### Class for Rectified Linear Unit (ReLU) Activation Function\n",
        "\n",
        "The code defines a Python class called `ReLU`, which represents the Rectified Linear Unit (ReLU) activation function. ReLU is a commonly used activation function in neural networks. Below is an explanation of the code:\n",
        "\n",
        "##### `__call__` Method:\n",
        "- The `__call__` method defines the forward pass of the ReLU activation function.\n",
        "- It takes a single argument, `Z`, which represents the input to the ReLU activation function.\n",
        "- Inside the method:\n",
        "  - It applies the ReLU activation element-wise to the input `Z` using the NumPy function `np.maximum(0, Z)`. This operation replaces all negative values in `Z` with zeros.\n",
        "  - The result of this operation is returned as the output of the ReLU activation function.\n",
        "\n",
        "##### `backward` Method:\n",
        "- The `backward` method defines the backward pass, which computes gradients during backpropagation for the ReLU activation function.\n",
        "- It takes two arguments: `Z` (the input to the ReLU) and `A` (the gradient of the output of the layer above, which corresponds to the input to the ReLU).\n",
        "- Inside the method:\n",
        "  - It copies the gradient `A.grad` from the layer above to the current layer `Z`. This step ensures that the gradient information is passed back.\n",
        "  - It sets the gradients to zero for elements in `Z` where the original input `Z` was less than or equal to 0. This step implements the derivative of the ReLU function, which is 1 for positive values and 0 for non-positive values. This ensures that the gradient remains zero for the negative part of the ReLU.\n",
        "\n",
        "The `ReLU` class is a building block used in neural networks to introduce non-linearity. It is particularly effective in deep learning because it helps mitigate the vanishing gradient problem and promotes sparse representations. When applied to the output of a linear layer, ReLU activations result in output values that are zero for negative inputs and unchanged for positive inputs during the forward pass.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spnElpB9q_uw"
      },
      "outputs": [],
      "source": [
        "class ReLU():\n",
        "    # Constructor method (__call__) for the ReLU activation function\n",
        "    def __call__(self, Z):\n",
        "        # Apply ReLU activation element-wise to the input Z and return the result.\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "    # Backward pass method to compute gradients during backpropagation\n",
        "    def backward(self, Z, A):\n",
        "        # Copy the gradient from the layer above (A) to the current layer (Z).\n",
        "        Z.grad = A.grad.copy()\n",
        "\n",
        "        # Set gradients to zero for elements where the original input Z was less than or equal to 0.\n",
        "        Z.grad[Z <= 0] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YiTfRjEq_uw"
      },
      "source": [
        "### Clase Sequential\n",
        "#### Class for Sequential Neural Network Layers\n",
        "\n",
        "The code defines a Python class called `Sequential_layers`, which represents a sequential neural network with layers. This class is designed to handle forward and backward passes, weight and bias updates, and making predictions. It's a simplified implementation of a neural network model. Below is an explanation of the code:\n",
        "\n",
        "##### `__init__` Method:\n",
        "- The `__init__` method is the constructor of the class, which initializes the neural network with a list of layers.\n",
        "- It takes a single argument, `layers`, which is a list containing objects of type `Linear` or `ReLU`. These layers represent the building blocks of the neural network.\n",
        "- Inside the constructor:\n",
        "  - The list of layers is stored as an instance variable `self.layers`.\n",
        "  - Instance variables `self.x` and `self.outputs` are initialized to `None` and an empty dictionary, respectively. These variables will be used to store input data and layer outputs during computation.\n",
        "\n",
        "##### `__call__` Method (Forward Pass):\n",
        "- The `__call__` method defines the forward pass of the neural network.\n",
        "- It takes an input tensor `X` as an argument.\n",
        "- Inside the method:\n",
        "  - The input data `X` is set as `self.x` to keep track of the input.\n",
        "  - The input data is stored as the output of the first layer ('l0') in `self.outputs`.\n",
        "  - The method iterates through the layers, applying each layer's forward pass operation sequentially. The output of one layer becomes the input to the next layer.\n",
        "  - The final output of the last layer is returned as the result of the forward pass.\n",
        "\n",
        "##### `backward` Method (Backward Pass for Gradients):\n",
        "- The `backward` method defines the backward pass, which computes gradients during backpropagation.\n",
        "- It iterates through the layers in reverse order.\n",
        "- For each layer, it calls the layer's `backward` method to compute gradients.\n",
        "- Gradients are propagated from the output of one layer to the input of the next layer.\n",
        "\n",
        "##### `update` Method (Weight and Bias Updates):\n",
        "- The `update` method updates the weights and biases of the layers using gradient descent.\n",
        "- It takes an optional `learning_rate` argument, which determines the step size for gradient descent.\n",
        "- For each layer, if the layer is of type `Linear`, it updates the weights and biases using gradient descent.\n",
        "\n",
        "##### `predict` Method (Making Predictions):\n",
        "- The `predict` method is used to make predictions using the trained model.\n",
        "- It takes an input tensor `X`.\n",
        "- It calls the `__call__` method to perform the forward pass and obtain the final output.\n",
        "- The predicted class is determined by finding the index of the maximum value in the output.\n",
        "\n",
        "This `Sequential_layers` class serves as a basic framework for implementing and training neural networks. It allows you to define a sequential architecture of layers, perform forward and backward passes, update model parameters, and make predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDlhJylfq_uw"
      },
      "outputs": [],
      "source": [
        "# Class that evaluates prediction and propagates corrections to weights and biases\n",
        "class Sequential_layers():\n",
        "    # Constructor method\n",
        "    def __init__(self, layers):\n",
        "        '''\n",
        "        layers - a list containing objects of type Linear or ReLU\n",
        "        '''\n",
        "        # Initialize the Sequential_layers object with a list of layers.\n",
        "        self.layers = layers\n",
        "\n",
        "        # Initialize instance variables to store input data and layer outputs.\n",
        "        self.x = None\n",
        "        self.outputs = {}\n",
        "\n",
        "    # Forward pass method\n",
        "    def __call__(self, X):\n",
        "        # Set the input data to X.\n",
        "        self.x = X\n",
        "\n",
        "        # Store the input data as the output of the first layer ('l0').\n",
        "        self.outputs['l0'] = self.x\n",
        "\n",
        "        # Iterate through the layers, applying each layer's forward pass operation.\n",
        "        for i, layer in enumerate(self.layers, 1):\n",
        "            self.x = layer(self.x)\n",
        "            self.outputs['l'+str(i)] = self.x\n",
        "\n",
        "        # Return the final output of the last layer.\n",
        "        return self.x\n",
        "\n",
        "    # Backward pass method for computing gradients\n",
        "    def backward(self):\n",
        "        # Iterate through the layers in reverse order.\n",
        "        for i in reversed(range(len(self.layers))):\n",
        "            # Call each layer's backward method to compute gradients.\n",
        "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
        "\n",
        "    # Update method for updating weights and biases using gradient descent\n",
        "    def update(self, learning_rate=1e-3):\n",
        "        for layer in self.layers:\n",
        "            # Skip layers of type ReLU in weight and bias updates.\n",
        "            if isinstance(layer, ReLU):\n",
        "                continue\n",
        "\n",
        "            # Update the weights and biases using gradient descent.\n",
        "            layer.W = layer.W - learning_rate * layer.W.grad\n",
        "            layer.b = layer.b - learning_rate * layer.b.grad\n",
        "\n",
        "    # Prediction method for making predictions using the trained model\n",
        "    def predict(self, X):\n",
        "        # Call the forward pass to get the final output and predict the class.\n",
        "        return np.argmax(self.__call__(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS0gwbSzq_uw"
      },
      "source": [
        "### Cost Function\n",
        "#### Evaluation Function for Softmax Activation with Cross-Entropy Loss\n",
        "\n",
        "The code defines a Python function called `softmaxXEntropy`, which computes the softmax activation and the cross-entropy loss for a set of input scores (`x`) and corresponding labels (`y`). This function is often used in the context of multiclass classification in machine learning. Below is an explanation of the code:\n",
        "\n",
        "##### Function Parameters:\n",
        "- `x`: A NumPy array containing input scores. The shape of `x` is assumed to be `(C, batch_size)`, where `C` is the number of classes, and `batch_size` is the number of samples in the batch.\n",
        "- `y`: A NumPy array containing the true labels corresponding to the input scores. The shape of `y` is assumed to be `(batch_size,)`.\n",
        "\n",
        "##### Computation Steps:\n",
        "\n",
        "1. **Batch Size Calculation**:\n",
        "   - The batch size is calculated from the input data `x` by examining its shape along the second dimension (`batch_size`). This is used for normalization in later steps.\n",
        "\n",
        "2. **Exponential Transformation**:\n",
        "   - The exponential of the input scores (`x`) is computed element-wise. This is done to convert the raw scores into positive values.\n",
        "\n",
        "3. **Probability Calculation**:\n",
        "   - The probabilities for each class are computed by dividing the exponential scores (`exp_scores`) by their sum along the specified axis (`axis=0`). This operation transforms the scores into a probability distribution.\n",
        "\n",
        "4. **Copy of Predicted Probabilities**:\n",
        "   - A copy of the computed probabilities (`probs`) is made and stored in `preds` for later use.\n",
        "\n",
        "5. **Label Reshaping**:\n",
        "   - The labels `y` are reshaped into a 2D array with a single column. This is done to match the shape required for indexing operations.\n",
        "\n",
        "6. **Cross-Entropy Loss Calculation**:\n",
        "   - The cross-entropy loss is calculated using the softmax probabilities. For each sample in the batch, it computes the negative log-likelihood of the true class. The loss is averaged across the batch.\n",
        "\n",
        "7. **Gradients Calculation for Backpropagation**:\n",
        "   - The gradients are computed for backpropagation. This involves modifying the `probs` array by subtracting 1 from the predicted class probabilities for each sample in the batch. The result is stored in the `x.grad` attribute.\n",
        "\n",
        "8. **Return Values**:\n",
        "   - The function returns two values:\n",
        "     - `preds`: The predicted class probabilities after applying the softmax activation.\n",
        "     - `cost`: The computed softmax cross-entropy loss for the batch.\n",
        "\n",
        "This `softmaxXEntropy` function is a fundamental component for training and evaluating neural networks, especially in multiclass classification tasks. It computes the probabilities of each class and the associated loss, which is used for training and optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGHFhdieq_uw"
      },
      "outputs": [],
      "source": [
        "# Evaluation function to convert ouptuts to probabilities; softMax\n",
        "def softmaxXEntropy(x, y):\n",
        "    # Get the batch size from the input data 'x'\n",
        "    batch_size = x.shape[1]\n",
        "\n",
        "    # Compute the exponential of the input scores ('x')\n",
        "    exp_scores = np.exp(x)\n",
        "\n",
        "    # Compute probabilities by dividing exp_scores by their sum along the specified axis (axis=0)\n",
        "    probs = exp_scores / exp_scores.sum(axis=0)\n",
        "\n",
        "    # Make a copy of 'probs' for later use\n",
        "    preds = probs.copy()\n",
        "\n",
        "    # Convert 'y' into a 2D array with a single column\n",
        "    y = y.reshape(1, -1)\n",
        "\n",
        "    # Calculate the cost using softmax cross-entropy loss\n",
        "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
        "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
        "\n",
        "    # Calculate gradients for backpropagation\n",
        "    probs[y.squeeze(), np.arange(batch_size)] -= 1  # dl/dx\n",
        "    x.grad = probs.copy()\n",
        "\n",
        "    # Return both the predicted probabilities and the computed cost\n",
        "    return preds, cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkUbA1Nbq_uw"
      },
      "source": [
        "### Loop de entrenamiento\n",
        "#### Training Loop\n",
        "\n",
        "The code defines a Python function called `train` that implements a training loop for training a machine learning model (typically a neural network) using stochastic gradient descent (SGD). The function trains the model for a specified number of epochs. Below is an explanation of the code:\n",
        "\n",
        "##### Function Parameters:\n",
        "- `model`: The machine learning model to be trained. This is an instance of the `Sequential_layers` class, as shown in previous code segments.\n",
        "- `epochs`: The number of training epochs, which specifies how many times the entire training dataset will be processed by the model.\n",
        "- `mb_size`: The mini-batch size, which determines the number of samples in each mini-batch used during training.\n",
        "- `learning_rate`: The learning rate, which controls the step size in gradient descent for updating model parameters.\n",
        "\n",
        "##### Training Loop:\n",
        "\n",
        "The training loop consists of the following steps:\n",
        "\n",
        "1. **Loop Over Epochs**:\n",
        "   - The outer loop iterates over the specified number of training epochs (`epochs`).\n",
        "\n",
        "2. **Mini-Batch Iteration**:\n",
        "   - Within each epoch, the training data is divided into mini-batches using the `create_minibatches` function. Each mini-batch contains `mb_size` samples.\n",
        "\n",
        "3. **Forward Pass**:\n",
        "   - For each mini-batch, a forward pass is performed using the model's `__call__` method to compute the scores (logits) for each class.\n",
        "\n",
        "4. **Cost Calculation and Gradient Computation**:\n",
        "   - The softmax cross-entropy cost is calculated by calling the `softmaxXEntropy` function, which computes the cost and gradients.\n",
        "   - The computed cost is ignored with `_` (underscore), but the gradients are computed and used for backpropagation.\n",
        "\n",
        "5. **Backpropagation**:\n",
        "   - The model's `backward` method is called to propagate gradients backward through the layers of the model.\n",
        "\n",
        "6. **Parameter Updates**:\n",
        "   - Model parameters (weights and biases) are updated using gradient descent. The `update` method of the model updates these parameters based on the computed gradients.\n",
        "\n",
        "7. **Printing Progress**:\n",
        "   - After processing each mini-batch, the code prints the cost and accuracy for the current epoch. The accuracy is calculated using the `accuracy` function, which is assumed to be defined elsewhere in the code.\n",
        "\n",
        "8. **End of Epoch**:\n",
        "   - The loop continues until all epochs are completed.\n",
        "\n",
        "The purpose of this `train` function is to train a machine learning model by iterating through the training dataset for a specified number of epochs and updating model parameters using gradient descent. It also provides feedback on the training progress by printing the cost and accuracy after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAgfvk6Aq_ux"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
        "    # Loop over the specified number of epochs\n",
        "    for epoch in range(epochs):\n",
        "        # Iterate through minibatches of training data\n",
        "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
        "            # Forward pass to compute scores from the model\n",
        "            scores = model(x.T.view(np_tensor))\n",
        "\n",
        "            # Calculate the softmax cross-entropy cost and compute gradients\n",
        "            _, cost = softmaxXEntropy(scores, y)\n",
        "            model.backward()\n",
        "\n",
        "            # Update model parameters (weights and biases) using gradient descent\n",
        "            model.update(learning_rate)\n",
        "\n",
        "        # Print cost and accuracy for the current epoch\n",
        "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK3WqXZ5q_ux"
      },
      "source": [
        "### Create your model and train it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqWn71zwq_ux"
      },
      "outputs": [],
      "source": [
        "# Evaluation metric; Accuracy\n",
        "def accuracy(x, y, mb_size):\n",
        "    # Initialize variables to count correct and total predictions\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterate through minibatches of input data 'x' and corresponding labels 'y'\n",
        "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
        "        # Make predictions for the current minibatch using the model\n",
        "        pred = model(x.T.view(np_tensor))\n",
        "\n",
        "        # Count the number of correct predictions in the minibatch\n",
        "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
        "\n",
        "        # Increment the total count by the number of predictions in the minibatch\n",
        "        total += pred.shape[1]\n",
        "\n",
        "    # Calculate and return the accuracy as the ratio of correct predictions to total predictions\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0iMkOQBq_ux"
      },
      "outputs": [],
      "source": [
        "# Model declaration with hyperparameters\n",
        "# Create a Sequential_layers model consisting of layers with specified dimensions\n",
        "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 24)])\n",
        "\n",
        "# Set the minibatch size for training\n",
        "mb_size = 512\n",
        "\n",
        "# Set the learning rate for gradient descent\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Set the number of training epochs\n",
        "epochs = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0LzpNbGq_ux",
        "outputId": "f6fc5aa8-f377-4fc8-946f-2afd0e74bb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "costo: 1.1484796491843459, accuracy: 0.5789180145008366\n",
            "costo: 0.5502522927218111, accuracy: 0.6497490239821528\n",
            "costo: 0.37107746535701575, accuracy: 0.692414947016174\n",
            "costo: 0.21743358278164204, accuracy: 0.716675962074735\n",
            "costo: 0.1626169940280107, accuracy: 0.718627997769102\n",
            "costo: 0.12634679406054447, accuracy: 0.7317345231455661\n",
            "costo: 0.08505866288520171, accuracy: 0.7345231455660903\n",
            "costo: 0.06310526393393884, accuracy: 0.7445621862799777\n",
            "costo: 0.05210968964215365, accuracy: 0.7426101505856108\n",
            "costo: 0.042721669860361314, accuracy: 0.752649191299498\n",
            "costo: 0.03930738695076031, accuracy: 0.7504182933630786\n",
            "costo: 0.03424006082112811, accuracy: 0.7548800892359174\n",
            "costo: 0.030963703330116603, accuracy: 0.7540435025097602\n",
            "costo: 0.031040003889341323, accuracy: 0.7548800892359174\n",
            "costo: 0.02256542010336864, accuracy: 0.756553262688232\n",
            "costo: 0.018978978949438438, accuracy: 0.7590630228667038\n",
            "costo: 0.01937078110734947, accuracy: 0.7576687116564417\n",
            "costo: 0.017097871432205647, accuracy: 0.7596207473508088\n",
            "costo: 0.015580309127867108, accuracy: 0.7598996095928612\n",
            "costo: 0.01733030594735541, accuracy: 0.762409369771333\n",
            "costo: 0.014803822777755231, accuracy: 0.7626882320133854\n",
            "costo: 0.014918872320915502, accuracy: 0.7635248187395427\n",
            "costo: 0.011749558668256966, accuracy: 0.7635248187395427\n",
            "costo: 0.013018716675440222, accuracy: 0.7626882320133854\n",
            "costo: 0.01007036842176725, accuracy: 0.7635248187395427\n",
            "costo: 0.011147911059723584, accuracy: 0.7643614054657\n",
            "costo: 0.009246090599434546, accuracy: 0.7646402677077524\n",
            "costo: 0.010467476784193805, accuracy: 0.7649191299498048\n",
            "costo: 0.0095287008209601, accuracy: 0.7657557166759621\n",
            "costo: 0.007812653688649236, accuracy: 0.7663134411600669\n",
            "costo: 0.0073935073390631306, accuracy: 0.7651979921918572\n",
            "costo: 0.008397343610587815, accuracy: 0.7660345789180145\n",
            "costo: 0.008476999977480127, accuracy: 0.7651979921918572\n",
            "costo: 0.005983641389271691, accuracy: 0.7663134411600669\n",
            "costo: 0.0077387775665564325, accuracy: 0.7671500278862242\n",
            "costo: 0.006921885931774767, accuracy: 0.7651979921918572\n",
            "costo: 0.0072634147161436385, accuracy: 0.7668711656441718\n",
            "costo: 0.006665527767732357, accuracy: 0.7671500278862242\n",
            "costo: 0.006110744303060858, accuracy: 0.7682654768544339\n",
            "costo: 0.005167179409563362, accuracy: 0.7671500278862242\n"
          ]
        }
      ],
      "source": [
        "# Training function for the declared model\n",
        "train(model, epochs, mb_size, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb6bOPb2q_ux",
        "outputId": "a1d8e5d2-5a64-4948-f200-e761e33ab155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7646402677077524\n"
          ]
        }
      ],
      "source": [
        "# Print the accuracy of model\n",
        "print(accuracy(x_test, y_test, mb_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Justification for Model Architecture Selection\n",
        "\n",
        "The code defines a machine learning model and training pipeline for a image classification task. Let's break down the justification for the selected model architecture:\n",
        "\n",
        "#### 1. Task Understanding:\n",
        "- The chosen architecture is designed for a specific machine learning task, on this case for a classification task with image data, which requires learning from input data and making predictions.\n",
        "\n",
        "#### 2. Sequential Neural Network:\n",
        "- The model architecture is implemented as a sequential neural network (`Sequential_layers`). This choice allows for easy stacking of layers, which is suitable for a wide range of tasks, including image classification.\n",
        "\n",
        "#### 3. Input Layer:\n",
        "- The model starts with an input layer (`Linear(784, 200)`), with a input data of 784 features. The task involves processing data with a high-dimensional input.\n",
        "\n",
        "#### 4. Hidden Layers:\n",
        "- The model contains multiple hidden layers, each followed by a Rectified Linear Unit (ReLU) activation function (`ReLU()`). This architecture leverages non-linear activations to capture complex relationships in the data. Multiple hidden layers can help the model learn hierarchical features.\n",
        "\n",
        "#### 5. Output Layer:\n",
        "   - The output layer in the model architecture is defined as a linear layer with 200 input units and 24 output units. This specification provides clarity on the dimensionality of the model's output.\n",
        "\n",
        "   - The choice of 24 output is because this is a classification problem with 24 possible classes. The linear output layer can produce unnormalized scores for each class, which can be further processed (e.g., using softmax) to obtain class probabilities.\n",
        "\n",
        "   - The inclusion of an output layer with the specified dimensions ensures that the model architecture is complete and suitable for the image classification.\n",
        "\n",
        "#### 5. Kaiming He Initialization:\n",
        "   - The code initializes the weights of the linear layers using Kaiming He initialization. This initialization technique is suitable for deep neural networks, ensuring stable and efficient training.\n",
        "\n",
        "#### 6. Gradient Descent Optimization:\n",
        "- The training loop uses stochastic gradient descent (SGD) for optimization. This is a widely used optimization algorithm for training neural networks.\n",
        "\n",
        "#### 7. Training and Evaluation:\n",
        "- The code includes functions for training the model (`train` function) and evaluating its accuracy (`accuracy` function). The model's performance will be assessed using accuracy as a metric.\n",
        "\n",
        "#### 8. Experimentation:\n",
        "- The code allows experimentation, making possible to do easy adjustments of hyperparameters, such as the mini-batch size, learning rate, and number of epochs. This is essential for fine-tuning the model's performance. In this case the minibatch size chosen was 512 (a number that is more easy to understand for the machine), a learning rate of 0.0001 or  $1 \\times 10^{-4}$, noted as ```1e-4``` in the code, and 40 epochs, these parameters used in the model gave us an accuracy of 76%.\n",
        "\n",
        "#### 9. Modular and Extensible:\n",
        "- The architecture is modular and extensible, this allows to add more layers or modify existing ones as needed for different tasks or datasets.\n",
        "\n",
        "#### 10. Training Loop and Feedback:\n",
        "- The training loop provides feedback during training by printing the cost and accuracy for each epoch. This helps monitor the model's progress and identify potential issues.\n"
      ],
      "metadata": {
        "id": "jPEtnpKW8G_p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rAF1EsPq_ux"
      },
      "source": [
        "### Test your model on Random data from your test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "Xb-J0eS4q_ux",
        "outputId": "e0e8eb22-cffd-452f-d982-30be991442a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor predicho es: i, el valor real es: i\n"
          ]
        }
      ],
      "source": [
        "# Pick a random sample, evaluate, and show results vs actual classification\n",
        "# Select a random index within the range of the test data.\n",
        "\n",
        "idx = np.random.randint(len(y_test))\n",
        "\n",
        "# Plot the image corresponding to the selected random test data point.\n",
        "plot_number(x_test[idx].reshape(28,28))\n",
        "\n",
        "# Make predictions for the selected test data point using the trained model.\n",
        "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
        "\n",
        "# Print the predicted value and the actual value (ground truth) for comparison.\n",
        "print(f'El valor predicho es: {alphabet[int(pred)]}, el valor real es: {alphabet[int(y_test[idx])]}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}