{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarmentamna/machine_learning_advance/blob/main/TC5033_Activity3b_42.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Maestría en Inteligencia Artificial Aplicada**\n",
        "### **Curso: ADVANCED MACHINE LEARNING METHODS**\n",
        "## Tecnológico de Monterrey\n",
        "### Dr. José Antonio Cantoral Ceballos\n",
        "\n",
        "## Activity Week 7\n",
        "### Text Classification using RNNs and AG_NEWS dataset in PyTorch\n",
        "\n",
        "*TEAM MEMBERS:*\n",
        "\n",
        "*   Roberto Romero Vielma - A00822314\n",
        "*   José Javier Granados Hernández - A00556717\n",
        "*   Aquiles Yonatan Armenta Hernandez - A01793252\n",
        "*   Alan Avelino Fernández Juárez - A00989308"
      ],
      "metadata": {
        "id": "jOu04coLH_rV"
      },
      "id": "jOu04coLH_rV"
    },
    {
      "cell_type": "markdown",
      "id": "940c6dbc",
      "metadata": {
        "id": "940c6dbc"
      },
      "source": [
        "## TC 5033\n",
        "### Word Embeddings\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Activity 3b: Text Classification using RNNs and AG_NEWS dataset in PyTorch\n",
        "<br>\n",
        "\n",
        "- Objective:\n",
        "    - Understand the basics of Recurrent Neural Networks (RNNs) and their application in text classification.\n",
        "    - Learn how to handle a real-world text dataset, AG_NEWS, in PyTorch.\n",
        "    - Gain hands-on experience in defining, training, and evaluating a text classification model in PyTorch.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Instructions:\n",
        "    - Data Preparation: Starter code will be provided that loads the AG_NEWS dataset and prepares it for training. Do not modify this part. However, you should be sure to understand it, and comment it, the use of markdown cells is suggested.\n",
        "\n",
        "    - Model Setup: A skeleton code for the RNN model class will be provided. Complete this class and use it to instantiate your model.\n",
        "\n",
        "    - Implementing Accuracy Function: Write a function that takes model predictions and ground truth labels as input and returns the model's accuracy.\n",
        "\n",
        "    - Training Function: Implement a function that performs training on the given model using the AG_NEWS dataset. Your model should achieve an accuracy of at least 80% to get full marks for this part.\n",
        "\n",
        "    - Text Sampling: Write a function that takes a sample text as input and classifies it using your trained model.\n",
        "\n",
        "    - Confusion Matrix: Implement a function to display the confusion matrix for your model on the test data.\n",
        "\n",
        "    - Submission: Submit your completed Jupyter Notebook. Make sure to include a markdown cell at the beginning of the notebook that lists the names of all team members. Teams should consist of 3 to 4 members.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Evaluation Criteria:\n",
        "\n",
        "    - Correct setup of all the required libraries and modules (10%)\n",
        "    - Code Quality (30%): Your code should be well-organized, clearly commented, and easy to follow. Use also markdown cells for clarity. Comments should be given for all the provided code, this will help you understand its functionality.\n",
        "    \n",
        "   - Functionality (60%):\n",
        "        - All the functions should execute without errors and provide the expected outputs.\n",
        "        - RNN model class (20%)\n",
        "        - Accuracy function (10%)\n",
        "        - Training function (10%)\n",
        "        - Sampling function (10%)\n",
        "        - Confucion matrix (10%)\n",
        "\n",
        "        - The model should achieve at least an 80% accuracy on the AG_NEWS test set for full marks in this criterion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de318da",
      "metadata": {
        "id": "4de318da"
      },
      "source": [
        "Dataset\n",
        "\n",
        "https://pytorch.org/text/stable/datasets.html#text-classification\n",
        "\n",
        "https://paperswithcode.com/dataset/ag-news\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a9801f9",
      "metadata": {
        "id": "4a9801f9"
      },
      "source": [
        "### Import libraries\n",
        "1. `import numpy as np`: The 'numpy' library is imported and aliased as 'np' for numerical operations.\n",
        "\n",
        "2. `import torch`: The PyTorch library is imported for deep learning tasks.\n",
        "\n",
        "3. `from torchtext.datasets import AG_NEWS`: The 'AG_NEWS' dataset is imported from the 'torchtext.datasets' module.\n",
        "\n",
        "4. `from torch.utils.data import DataLoader`: The 'DataLoader' class is imported from the 'torch.utils.data' module.\n",
        "\n",
        "5. `from torch.utils.data.dataset import random_split`: The 'random_split' function is imported from the 'torch.utils.data.dataset' module.\n",
        "\n",
        "6. `from torchtext.data.utils import get_tokenizer`: The 'get_tokenizer' function is imported from 'torchtext.data.utils'.\n",
        "\n",
        "7. `from torchtext.vocab import build_vocab_from_iterator`: The 'build_vocab_from_iterator' function is imported from 'torchtext.vocab'.\n",
        "\n",
        "8. `from torchtext.data.functional import to_map_style_dataset`: The 'to_map_style_dataset' function is imported from 'torchtext.data.functional'.\n",
        "\n",
        "9. `from torch import nn`: The 'nn' module from PyTorch is imported for building neural network layers.\n",
        "\n",
        "10. `from torch.nn import functional as F`: The 'F' module from 'torch.nn' is imported for functional operations in neural networks.\n",
        "\n",
        "11. `import scikitplot as skplt`: The 'scikitplot' library is imported and aliased as 'skplt.' This library is suggested for plotting confusion matrices.\n",
        "\n",
        "12. `import gc`: The 'gc' (garbage collector) module is imported for memory management and cleanup.\n",
        "\n",
        "The code prepares the environment by importing the required libraries, making them available for further tasks such as data preprocessing, model building, and evaluation, including the plotting of confusion matrices using 'scikitplot.'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the 'scikit-plot' library using pip.\n",
        "!pip install scikit-plot\n",
        "\n",
        "# Install 'portalocker' library with a minimum version requirement of 2.0.0 using pip.\n",
        "!pip install portalocker>=2.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hul1RkPoJXD-",
        "outputId": "13e1d284-c07d-4885-f6dd-63984cb5317f"
      },
      "id": "hul1RkPoJXD-",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.11.3)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "878b524f",
      "metadata": {
        "id": "878b524f"
      },
      "outputs": [],
      "source": [
        "import numpy as np # Import the 'numpy' library and alias it as 'np' for numerical operations.\n",
        "\n",
        "# PyTorch libraries\n",
        "import torch # Import the PyTorch library for deep learning tasks.\n",
        "from torchtext.datasets import AG_NEWS # Import the 'AG_NEWS' dataset from the 'torchtext.datasets' module.\n",
        "\n",
        "# Dataloader library\n",
        "from torch.utils.data import DataLoader # Import the 'DataLoader' class from the 'torch.utils.data' module.\n",
        "from torch.utils.data.dataset import random_split # Import the 'random_split' function from the 'torch.utils.data.dataset' module.\n",
        "\n",
        "# Libraries to prepare the data\n",
        "from torchtext.data.utils import get_tokenizer # Import the 'get_tokenizer' function from 'torchtext.data.utils'.\n",
        "from torchtext.vocab import build_vocab_from_iterator # Import 'build_vocab_from_iterator' function from 'torchtext.vocab'.\n",
        "from torchtext.data.functional import to_map_style_dataset # Import the 'to_map_style_dataset' function from 'torchtext.data.functional'.\n",
        "\n",
        "\n",
        "# Neural Layers\n",
        "from torch import nn # Import the 'nn' module from PyTorch for building neural network layers.\n",
        "from torch.nn import functional as F # Import the 'F' module from 'torch.nn' for functional operations in neural networks.\n",
        "\n",
        "# Plot a confusion matrix\n",
        "import scikitplot as skplt # Import the 'scikitplot' library and alias it as 'skplt' for confusion matrix plotting.\n",
        "\n",
        "import gc # Import the 'gc' (garbage collector) module for memory management and cleanup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "3bab55f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bab55f3",
        "outputId": "127feb72-643c-4335-d06e-1e0a6f81b3c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if a CUDA-compatible GPU is available; if yes, use CUDA, otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Print the selected device (CUDA or CPU)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d38956d",
      "metadata": {
        "id": "3d38956d"
      },
      "source": [
        "### Get the train and the test datasets and dataloaders\n",
        "The following code demonstrates various steps in data preprocessing and dataset splitting for a machine learning or deep learning task.\n",
        "\n",
        "#### Data Loading and Dataset Splitting\n",
        "\n",
        "1. **Load the AG_NEWS dataset and Split:** Initially, the AG_NEWS dataset is loaded and then split into two datasets: `train_dataset` and `test_dataset`.\n",
        "\n",
        "2. **Convert to Map-Style Datasets:** Both the training and testing datasets are converted to map-style datasets using the `to_map_style_dataset` function. Map-style datasets are a common format for data processing in PyTorch.\n",
        "\n",
        "#### Tokenization and Vocabulary Building\n",
        "\n",
        "3. **Tokenization Setup:** A tokenizer is defined using the 'basic_english' configuration, which is suitable for processing English text.\n",
        "\n",
        "4. **Token Yielding Function:** A function named `yield_tokens` is defined to extract tokens from the given data. It iterates through the data and tokenizes the text using the `tokeniser`.\n",
        "\n",
        "5. **Vocabulary Building:** A vocabulary is built from the tokens yielded by the `yield_tokens` function, with the special token \"<unk>\" used to represent unknown words. The vocabulary is created using the `build_vocab_from_iterator` function.\n",
        "\n",
        "6. **Default Index Set:** The default index of the vocabulary is set to \"<unk>\" to handle out-of-vocabulary words. If a token is not found in the vocabulary, it defaults to \"<unk>.\"\n",
        "\n",
        "#### Tokenization and Data Splitting\n",
        "\n",
        "7. **Tokenization of Input Text:** The input text, \"Welcome to TE3007,\" is tokenized using the 'tokeniser.'\n",
        "\n",
        "8. **Validation Dataset Size Calculation:** The code calculates the number of samples for the training and validation datasets. It reserves 90% of the data for training and assigns the remaining for validation.\n",
        "\n",
        "9. **Training and Validation Split:** The training dataset is split into two sets, `train_dataset` (containing `NUM_TRAIN` samples for training) and `val_dataset` (containing `NUM_VAL` samples for validation).\n",
        "\n",
        "#### Dataset Lengths\n",
        "\n",
        "10. **Dataset Lengths:** Finally, the lengths of the training, validation, and test datasets are printed to provide insights into the size of each dataset. This information is crucial for data preparation and model training.\n",
        "\n",
        "This code demonstrates essential steps in data preprocessing, including tokenization, vocabulary building, and dataset splitting, to prepare the data for subsequent deep learning tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9c6b784",
      "metadata": {
        "id": "e9c6b784"
      },
      "source": [
        "Classes:\n",
        "\n",
        "* 1 - World\n",
        "\n",
        "* 2 - Sports\n",
        "\n",
        "* 3 - Business\n",
        "\n",
        "* 4 - Sci/Tech\n",
        "\n",
        "We will convert them to:\n",
        "\n",
        "* 0 - World\n",
        "\n",
        "* 1 - Sports\n",
        "\n",
        "* 2 - Business\n",
        "\n",
        "* 3 - Sci/Tech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "49fbed19",
      "metadata": {
        "id": "49fbed19"
      },
      "outputs": [],
      "source": [
        "# Load the AG_NEWS dataset and split it into training and testing datasets\n",
        "train_dataset, test_dataset = AG_NEWS()\n",
        "# Convert the datasets to map-style datasets\n",
        "train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "9c372eb9",
      "metadata": {
        "id": "9c372eb9"
      },
      "outputs": [],
      "source": [
        "# Define a tokenizer using the 'basic_english' configuration\n",
        "tokeniser = get_tokenizer('basic_english')\n",
        "\n",
        "# Define a function to yield tokens from the given data\n",
        "def yield_tokens(data):\n",
        "    for _, text in data:\n",
        "        # Tokenize the text using the previously defined 'tokeniser'\n",
        "        yield tokeniser(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "794d0375",
      "metadata": {
        "id": "794d0375"
      },
      "outputs": [],
      "source": [
        "# Build a vocabulary from the tokens yielded by the 'yield_tokens' function on the training dataset\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_dataset), specials=[\"<unk>\"])\n",
        "# The 'specials' argument specifies special tokens, and \"<unk>\" is used for unknown words.\n",
        "\n",
        "# Set the default index of the vocabulary to \"<unk>\" (unknown) token\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "# This ensures that if a token is not found in the vocabulary, it defaults to \"<unk>\" for handling out-of-vocabulary words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "b48268d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b48268d4",
        "outputId": "59b3da2a-0466-4ac8-e4f8-1c064e42bf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['welcome', 'to', 'te3007'] [3314, 4, 0]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the input text using the 'tokeniser'\n",
        "tokens = tokeniser('Welcome to TE3007')\n",
        "# Print the original tokens and their corresponding indices\n",
        "print(tokens, vocab(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "c8c8f6a6",
      "metadata": {
        "id": "c8c8f6a6"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of samples for the training dataset by taking 90% of the entire dataset.\n",
        "NUM_TRAIN = int(len(train_dataset) * 0.9)\n",
        "\n",
        "# Calculate the number of samples for the validation dataset by subtracting the training dataset size from the total dataset size.\n",
        "NUM_VAL = len(train_dataset) - NUM_TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "8290895e",
      "metadata": {
        "id": "8290895e"
      },
      "outputs": [],
      "source": [
        "# Split the training dataset into training and validation datasets\n",
        "train_dataset, val_dataset = random_split(train_dataset, [NUM_TRAIN, NUM_VAL])\n",
        "\n",
        "# 'train_dataset' now contains NUM_TRAIN samples for training.\n",
        "# 'val_dataset' now contains NUM_VAL samples for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "cbc75b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbc75b54",
        "outputId": "c42333f6-1da5-4cfd-ab3e-2ec974206192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108000 12000 7600\n"
          ]
        }
      ],
      "source": [
        "# Print the lengths of the training, validation, and test datasets\n",
        "print(len(train_dataset), len(val_dataset), len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Collation Function\n",
        "\n",
        "1. **Splitting Labels and Text Data:** The function starts by receiving a batch of data. It separates the labels (y) and text data (x) using the `list(zip(*batch))` operation.\n",
        "\n",
        "2. **Tokenization and Numerical Conversion:** It then tokenizes the text data using a previously defined tokenizer (`tokeniser`) and converts the tokens to numerical representations using a vocabulary (`vocab`).\n",
        "\n",
        "3. **Padding and Truncation:** To ensure that all sequences have the same length for efficient processing, the function checks the length of each sequence. If a sequence is shorter than a predefined maximum length (`max_tokens`), it is padded with zeros to match the maximum length. If it's longer, it's truncated to the maximum length.\n",
        "\n",
        "4. **Data Type Conversion:** Finally, the function converts the processed data into PyTorch tensors. The text data is represented as a tensor with data type `torch.int32`, and the labels are adjusted by subtracting 1 from them and represented as tensors with the same data type."
      ],
      "metadata": {
        "id": "RdKyl2j65pg6"
      },
      "id": "RdKyl2j65pg6"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "ffdbf077",
      "metadata": {
        "id": "ffdbf077"
      },
      "outputs": [],
      "source": [
        "# Define a function for batch collation\n",
        "def collate_batch(batch):\n",
        "    # Split the batch into labels (y) and text data (x)\n",
        "    y, x = list(zip(*batch))\n",
        "\n",
        "    # Tokenize the text data and convert to numerical representations using the vocabulary\n",
        "    x = [vocab(tokeniser(text)) for text in x]\n",
        "\n",
        "    # Pad or truncate sequences to a maximum length (max_tokens)\n",
        "    x = [t + ([0] * (max_tokens - len(t))) if len(t) < max_tokens else t[:max_tokens] for t in x]\n",
        "\n",
        "    # Convert the tokenized and padded/truncated sequences to PyTorch tensors\n",
        "    return torch.tensor(x, dtype=torch.int32), torch.tensor(y, dtype=torch.int32) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "5eb459c7",
      "metadata": {
        "id": "5eb459c7"
      },
      "outputs": [],
      "source": [
        "# Define a list of labels for the AG_NEWS dataset\n",
        "labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "\n",
        "# Define the maximum number of tokens allowed in a sequence\n",
        "max_tokens = 50\n",
        "\n",
        "# Define the batch size for training and data processing\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "0a55e6ee",
      "metadata": {
        "id": "0a55e6ee"
      },
      "outputs": [],
      "source": [
        "# Create a DataLoader for the training dataset with a specified batch size and data processing function\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle=True)\n",
        "\n",
        "# Create a DataLoader for the validation dataset with the same batch size and processing function\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle=True)\n",
        "\n",
        "# Create a DataLoader for the test dataset with the same batch size and processing function\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b98898",
      "metadata": {
        "id": "47b98898"
      },
      "source": [
        "### Let us build our RNN model\n",
        "The following code defines a custom recurrent neural network (RNN) model class named `RNN_Model_1` for sequence classification tasks.\n",
        "\n",
        "#### Model Architecture\n",
        "\n",
        "1. **Initialization:** In the constructor (`__init__`), the model is initialized with the following parameters:\n",
        "    - `embed_size`: The size of the word embedding vectors.\n",
        "    - `hidden`: The number of hidden units in the RNN layer.\n",
        "    - `layers`: The number of stacked RNN layers.\n",
        "    - `num_classes`: The number of classes in the classification task.\n",
        "\n",
        "2. **Embedding Layer:** An embedding layer is created using the `nn.Embedding` module. This layer converts input tokens to dense vectors. The `num_embeddings` parameter is set to the length of the vocabulary (`len(vocab)`) to match the vocabulary size, and the `embedding_dim` is set to the specified `embed_size`.\n",
        "\n",
        "3. **RNN (GRU) Layer:** An RNN layer, specifically a Gated Recurrent Unit (GRU) layer, is created using `nn.GRU`. It takes the embedded input and processes it through recurrent layers. The `input_size` is set to `embed_size`, the `hidden_size` to `hidden`, the `num_layers` to `layers`, and `batch_first` is set to `True`.\n",
        "\n",
        "4. **Fully Connected Layer:** A fully connected layer is created using `nn.Linear`. It is used for the final classification. The `input_size` is `hidden`, and the `output_size` is `num_classes`.\n",
        "\n",
        "### Forward Pass\n",
        "\n",
        "The `forward` method specifies how data is passed through the model:\n",
        "1. The input `x` is first cast to `torch.int64` to ensure the correct data type.\n",
        "2. The input sequence is embedded using the previously defined embedding layer.\n",
        "3. The embedded sequence is passed through the GRU layer to capture sequential information.\n",
        "4. The output from the RNN layer is extracted from the last time step.\n",
        "5. Finally, the output is passed through the fully connected layer for classification.\n",
        "\n",
        "This model architecture is designed for sequence classification tasks, such as text classification, where the input sequence is processed to make class predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "50f20793",
      "metadata": {
        "id": "50f20793"
      },
      "outputs": [],
      "source": [
        "# Define the embedding size for word embeddings in the model\n",
        "EMBEDDING_SIZE = 100\n",
        "\n",
        "# Define the number of neurons in each hidden layer of the neural network\n",
        "NEURONS = 64\n",
        "\n",
        "# Define the number of layers in the neural network\n",
        "LAYERS = 2\n",
        "\n",
        "# Define the number of classes in the classification task\n",
        "NUM_CLASSES = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "0f7f5621",
      "metadata": {
        "id": "0f7f5621"
      },
      "outputs": [],
      "source": [
        "# Define a custom RNN model class (RNN_Model_1)\n",
        "class RNN_Model_1(nn.Module):\n",
        "    def __init__(self, embed_size, hidden, layers, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Create an embedding layer for converting input tokens to dense vectors\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab),\n",
        "                                            embedding_dim=embed_size)\n",
        "        # 'vocab' should be defined previously and represents the vocabulary for the dataset.\n",
        "\n",
        "        # Create an RNN (GRU) layer for sequence processing\n",
        "        self.rnn = nn.GRU(input_size=embed_size, hidden_size=hidden, num_layers=layers, batch_first=True)\n",
        "\n",
        "        # Create a fully connected layer for classification\n",
        "        self.fc = nn.Linear(hidden, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(torch.int64)  # Ensure the input is of type 'torch.int64'\n",
        "\n",
        "        # Embed the input sequence\n",
        "        embedded = self.embedding_layer(x)\n",
        "\n",
        "        # Pass the embedded sequence through the RNN layer\n",
        "        output, _ = self.rnn(embedded)\n",
        "\n",
        "        # Extract the output at the last time step of the sequence\n",
        "        output = output[:, -1, :]\n",
        "\n",
        "        # Pass the output through the fully connected layer for classification\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy\n",
        "\n",
        "The code below defines a function named `accuracy` for calculating the accuracy of a given model on a specified data loader. The function returns the accuracy as a floating-point value.\n",
        "\n",
        "#### Accuracy Calculation\n",
        "\n",
        "1. **Initialization:** Inside the `accuracy` function, two variables are initialized:\n",
        "   - `num_correct`: A counter for the number of correctly predicted instances.\n",
        "   - `num_total`: A counter for the total number of instances.\n",
        "\n",
        "2. **Model Evaluation:** The model is set to evaluation mode using `model.eval()`. This is important for ensuring that layers like dropout and batch normalization behave differently during evaluation compared to training.\n",
        "\n",
        "3. **Device Configuration:** The model is moved to the specified device (e.g., GPU or CPU) using `model.to(device=device)` to ensure that calculations are performed on the selected device.\n",
        "\n",
        "4. **Accuracy Computation:** The function iterates through the data loader. For each batch of data:\n",
        "   - The input (`x`) and target labels (`y`) are moved to the same device as the model with appropriate data types.\n",
        "   - The model is used to predict scores for the input data (`scores`).\n",
        "   - The predictions with the highest scores are obtained using `scores.max(dim=1)`.\n",
        "   - Correct predictions are counted by comparing the predictions to the true labels (`y`), and the number of correct predictions is added to `num_correct`.\n",
        "   - The total number of instances in the batch is added to `num_total`.\n",
        "\n",
        "5. **Accuracy Calculation:** The final accuracy is computed by dividing the number of correct predictions (`num_correct`) by the total number of instances (`num_total`). The result is returned as a floating-point value.\n"
      ],
      "metadata": {
        "id": "rMov-QDX8Bgx"
      },
      "id": "rMov-QDX8Bgx"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "2a42613f",
      "metadata": {
        "code_folding": [],
        "id": "2a42613f"
      },
      "outputs": [],
      "source": [
        "# Define a function for calculating the accuracy of a given model on a specified data loader\n",
        "def accuracy(model, loader):\n",
        "    num_correct = 0  # Initialize a counter for the number of correctly predicted instances\n",
        "    num_total = 0  # Initialize a counter for the total number of instances\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    model = model.to(device=device)  # Move the model to the specified device\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient tracking during inference\n",
        "        for x, y in loader:  # Iterate through the data loader\n",
        "            x = x.to(device=device, dtype=torch.float32)  # Move input data to the device with the appropriate data type\n",
        "            y = y.to(device=device, dtype=torch.long)  # Move target labels to the device with the appropriate data type\n",
        "            scores = model(x)  # Use the model to predict scores for the input data\n",
        "            _, predictions = scores.max(dim=1)  # Find the class with the highest score for each instance\n",
        "            num_correct += (predictions == y).sum()  # Count the number of correct predictions in the batch\n",
        "            num_total += predictions.size(0)  # Add the total number of instances in the batch to the counter\n",
        "\n",
        "    return float(num_correct / num_total)  # Compute and return the accuracy as a floating-point value"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "\n",
        "The following code defines a training function for deep learning model. This function is responsible for training the model over multiple epochs using the specified data loader and optimizing the model's parameters using an optimizer.\n",
        "\n",
        "### Function Overview\n",
        "\n",
        "The `train` function has the following components:\n",
        "\n",
        "1. **Model and Device Configuration:**\n",
        "   - The function starts by moving the model to the specified device (CPU or GPU) using `model.to(device=device)`. This ensures that all computations occur on the selected hardware.\n",
        "   \n",
        "2. **Epochs Loop:**\n",
        "   - The training process is executed for a specified number of training epochs. The outer loop iterates over each epoch using `for epoch in range(epochs)`.\n",
        "\n",
        "3. **Data Loading:**\n",
        "   - Within each epoch, the inner loop iterates over the training data using `for i, (x, y) in enumerate(train_loader)`. This loop allows the model to process the entire training dataset in batches.\n",
        "\n",
        "4. **Training Mode:**\n",
        "   - The model is set in training mode with `model.train()`. This is necessary to enable gradient computation and backpropagation during training.\n",
        "\n",
        "5. **Data Preparation:**\n",
        "   - Input data (`x`) is moved to the specified device with the appropriate data type (`dtype=torch.float32`), and target labels (`y`) are also moved to the device with the appropriate data type (`dtype=torch.long`).\n",
        "\n",
        "6. **Forward Pass and Loss Computation:**\n",
        "   - The model is used to predict scores for the input data (`scores`).\n",
        "   - The cross-entropy loss is computed using `F.cross_entropy`. This loss quantifies the error between predicted scores and true labels.\n",
        "\n",
        "7. **Gradient Computation:**\n",
        "   - The gradients are cleared to prevent gradient accumulation with `optimiser.zero_grad()`.\n",
        "   - Backpropagation is performed using `cost.backward()` to compute gradients.\n",
        "\n",
        "8. **Parameter Update:**\n",
        "   - The model's parameters are updated using the optimizer (`optimiser`) with `optimiser.step()`.\n",
        "\n",
        "9. **Validation and Logging:**\n",
        "   - After each epoch, the accuracy of the model on the validation set is calculated using the `accuracy` function.\n",
        "   - Training statistics such as the current epoch, cost (loss), and accuracy are printed to monitor the training progress using `print(f'Epoch: {epoch}, cost: {cost.item()}, accuracy: {acc}.')`.\n",
        "\n",
        "This `train` function is a fundamental component for training machine learning models. It encapsulates the process of forward and backward passes, parameter updates, and performance monitoring over multiple training epochs.\n"
      ],
      "metadata": {
        "id": "UMYUBCi38p4M"
      },
      "id": "UMYUBCi38p4M"
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "5e843e1f",
      "metadata": {
        "code_folding": [],
        "id": "5e843e1f"
      },
      "outputs": [],
      "source": [
        "# Define a training function for a machine learning model.\n",
        "def train(model, optimizer, epochs=100):\n",
        "    model = model.to(device=device)  # Move the model to the specified device (CPU or GPU).\n",
        "\n",
        "    for epoch in range(epochs):  # Iterate over the specified number of training epochs.\n",
        "        for i, (x, y) in enumerate(train_loader):  # Loop through the training data.\n",
        "            model.train()  # Set the model in training mode to enable gradient computation.\n",
        "            x = x.to(device=device, dtype=torch.float32)  # Move input data to the specified device with the appropriate data type.\n",
        "            y = y.to(device=device, dtype=torch.long)  # Move target labels to the specified device with the appropriate data type.\n",
        "            scores = model(x)  # Get the model's predicted scores.\n",
        "            cost = F.cross_entropy(input=scores, target=y)  # Calculate the cross-entropy loss.\n",
        "            optimizer.zero_grad()  # Zero the gradients to prevent gradient accumulation.\n",
        "            cost.backward()  # Perform backpropagation to compute gradients.\n",
        "            optimizer.step()  # Update model parameters using the optimizer.\n",
        "\n",
        "        acc = accuracy(model, val_loader)  # Calculate the accuracy of the model on the validation set.\n",
        "        print(f'Epoch: {epoch+1}/{epochs}, Loss: {cost.item()}, Accuracy: {acc}') # Print training statistics including the current epoch, loss, and accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "87775b29",
      "metadata": {
        "id": "87775b29"
      },
      "outputs": [],
      "source": [
        "# Set the number of training epochs to 20 for model training.\n",
        "epochs = 20\n",
        "\n",
        "# Set the learning rate (lr) to 0.001 for the Adam optimizer.\n",
        "lr = 0.001\n",
        "\n",
        "# Create an instance of the RNN model (RNN_Model_1) with specified parameters.\n",
        "rnn_model = RNN_Model_1(EMBEDDING_SIZE, NEURONS, LAYERS, NUM_CLASSES)\n",
        "\n",
        "# Initialize the optimizer (Adam) for updating the model's parameters with the specified learning rate (lr).\n",
        "optimiser = torch.optim.Adam(rnn_model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "aec12a1b",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aec12a1b",
        "outputId": "ee618499-5c9c-4611-fb4a-cfa8e3d44a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/20, Loss: 0.3658716678619385, Accuracy: 0.8713333010673523\n",
            "Epoch: 2/20, Loss: 0.314387708902359, Accuracy: 0.8968333005905151\n",
            "Epoch: 3/20, Loss: 0.23309548199176788, Accuracy: 0.9011666774749756\n",
            "Epoch: 4/20, Loss: 0.19882424175739288, Accuracy: 0.9112499952316284\n",
            "Epoch: 5/20, Loss: 0.10361933708190918, Accuracy: 0.9121666550636292\n",
            "Epoch: 6/20, Loss: 0.14485107362270355, Accuracy: 0.9082499742507935\n",
            "Epoch: 7/20, Loss: 0.06399103254079819, Accuracy: 0.9049166440963745\n",
            "Epoch: 8/20, Loss: 0.08748035877943039, Accuracy: 0.9053333401679993\n",
            "Epoch: 9/20, Loss: 0.03201404586434364, Accuracy: 0.9059166312217712\n",
            "Epoch: 10/20, Loss: 0.020157337188720703, Accuracy: 0.906000018119812\n",
            "Epoch: 11/20, Loss: 0.021070091053843498, Accuracy: 0.9016666412353516\n",
            "Epoch: 12/20, Loss: 0.044280149042606354, Accuracy: 0.9047499895095825\n",
            "Epoch: 13/20, Loss: 0.01573999784886837, Accuracy: 0.9005833268165588\n",
            "Epoch: 14/20, Loss: 0.02248699590563774, Accuracy: 0.8989999890327454\n",
            "Epoch: 15/20, Loss: 0.03896326944231987, Accuracy: 0.9054166674613953\n",
            "Epoch: 16/20, Loss: 0.017486190423369408, Accuracy: 0.9052500128746033\n",
            "Epoch: 17/20, Loss: 0.014792737551033497, Accuracy: 0.9021666646003723\n",
            "Epoch: 18/20, Loss: 0.04991108551621437, Accuracy: 0.903416633605957\n",
            "Epoch: 19/20, Loss: 0.003922170493751764, Accuracy: 0.9028333425521851\n",
            "Epoch: 20/20, Loss: 0.02203693613409996, Accuracy: 0.9002500176429749\n"
          ]
        }
      ],
      "source": [
        "# Train the RNN model using the provided optimizer and the specified number of training epochs.\n",
        "train(rnn_model, optimiser, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "7a3ef175",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a3ef175",
        "outputId": "981dab09-1559-4be6-c388-53cdb8f8b143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8962\n"
          ]
        }
      ],
      "source": [
        "# Print and display the test accuracy of the trained RNN model on the test dataset with four decimal places.\n",
        "print(f'accuracy: {accuracy(rnn_model, test_loader):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sample_text Function**\n",
        "\n",
        "The `sample_text` function is designed to classify a sample text using a previously trained model. The following details its functionality:\n",
        "\n",
        "#### Input Parameters:\n",
        "\n",
        "- `model`: The pre-trained model to be used for classification.\n",
        "- `loader`: The data loader that contains necessary information, such as vocabulary and device settings, for processing the sample text.\n",
        "- `sample_text`: The text to be classified.\n",
        "\n",
        "#### Flow of Operation:\n",
        "\n",
        "1. **Evaluation Mode:** The function begins by setting the model to evaluation mode using `model.eval()`. This ensures that the model does not make parameter adjustments during classification.\n",
        "\n",
        "2. **Tokenization:** The sample text is tokenized using the same tokenizer that was used during training. This ensures that the sample text is processed in the same way as the training data.\n",
        "\n",
        "3. **Conversion to Tensor:** Tokens generated from the sample text are converted into a tensor and moved to the same device as the model using `torch.tensor([vocab(tokens)], dtype=torch.int64).to(device=device)`. This is necessary for the model to make predictions on the same device.\n",
        "\n",
        "4. **Class Prediction:** The function uses the model to predict scores for the sample text. The scores represent the probability of belonging to each class. The class with the highest score (argmax) is sought to determine the predicted class.\n",
        "\n",
        "5. **Output:** The function returns the index of the predicted class as the result, allowing the identification of the class to which the sample text is assigned."
      ],
      "metadata": {
        "id": "U77ZexAhBPpl"
      },
      "id": "U77ZexAhBPpl"
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "ed30693d",
      "metadata": {
        "id": "ed30693d"
      },
      "outputs": [],
      "source": [
        "def sample_text(model, loader, sample_text):\n",
        "    model.eval()  # Set the model in evaluation mode.\n",
        "\n",
        "    # Tokenize the sample text using the same tokenizer used for training.\n",
        "    tokens = get_tokenizer('basic_english')(sample_text)\n",
        "\n",
        "    # Convert tokens to a tensor and move it to the same device as the model.\n",
        "    input_tensor = torch.tensor([vocab(tokens)], dtype=torch.int64).to(device=device)\n",
        "\n",
        "    # Use the model to predict scores for the input text.\n",
        "    with torch.no_grad():\n",
        "        scores = model(input_tensor)\n",
        "\n",
        "    # Find the class with the highest score (argmax) as the predicted class.\n",
        "    _, predicted_class = scores.max(dim=1)\n",
        "\n",
        "    return labels[predicted_class.item()]  # Return the predicted class index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "534f0220",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "534f0220",
        "outputId": "183715de-74e1-49d1-99aa-8bd759dedee7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Business'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "sample_text(rnn_model, test_loader, 'Mexico is located in North America') # Testing sample_text function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to Create a Confusion Matrix for Classification\n",
        "\n",
        "This function takes a trained PyTorch model and a data loader, evaluates the model on the data loader, and generates a confusion matrix using scikit-learn's `plot_confusion_matrix` function.\n",
        "\n",
        "#### Function Steps\n",
        "\n",
        "1. **Set Model to Evaluation Mode:**\n",
        "   - `model.eval()`: Sets the model in evaluation mode to disable training-specific behavior. During evaluation, the model won't update its weights.\n",
        "\n",
        "2. **Initialize Lists for True and Predicted Labels:**\n",
        "   - `true_labels` and `predicted_labels` are empty lists that will store the true labels and predicted labels, respectively.\n",
        "\n",
        "3. **Disable Gradient Computation:**\n",
        "   - `with torch.no_grad()`: Disables gradient computation for this part of the code to save memory. We don't need gradients during evaluation.\n",
        "\n",
        "4. **Iterate Over the Data Loader:**\n",
        "   - Iterate over the data loader to get input data and their corresponding true labels.\n",
        "\n",
        "5. **Move Data to Specified Device (e.g., GPU):**\n",
        "   - `inputs, labels = inputs.to(device), labels.to(device)`: Moves the input data and true labels to the specified device, such as a GPU.\n",
        "\n",
        "6. **Get Model Predictions:**\n",
        "   - `output = model(inputs)`: Passes the input data through the model to get predictions. These predictions are represented as scores for each class.\n",
        "\n",
        "7. **Find Predicted Classes:**\n",
        "   - `_, predicted = torch.max(output, 1)`: Finds the class with the highest score for each input, determining the predicted class.\n",
        "\n",
        "8. **Extend Lists with Batch Data:**\n",
        "   - `true_labels.extend(labels.cpu().numpy())` and `predicted_labels.extend(predicted.cpu().numpy())`: Extend the `true_labels` and `predicted_labels` lists with the true labels and predicted labels from the current batch. Converting to NumPy arrays makes it easier to work with.\n",
        "\n",
        "9. **Create the Confusion Matrix:**\n",
        "   - `skplt.metrics.plot_confusion_matrix(true_labels, predicted_labels, figsize=(8, 6))`: Creates the confusion matrix using scikit-learn's `plot_confusion_matrix` function, visualizing the performance of the model."
      ],
      "metadata": {
        "id": "XyXCzCgbEU08"
      },
      "id": "XyXCzCgbEU08"
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "bb38e093",
      "metadata": {
        "id": "bb38e093"
      },
      "outputs": [],
      "source": [
        "def create_confusion_matrix(model, data_loader):\n",
        "    # Set the model in evaluation mode to disable training-specific behavior\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize empty lists to store true and predicted labels\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    # Disable gradient computation for this part to save memory\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the data loader to get inputs and labels\n",
        "        for data in data_loader:\n",
        "            inputs, labels = data\n",
        "\n",
        "            # Move inputs and labels to the specified device (e.g., GPU)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Get model predictions for the inputs\n",
        "            output = model(inputs)\n",
        "\n",
        "            # Find the class with the highest score as the predicted class\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "            # Extend the true_labels and predicted_labels lists with data from the current batch\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Create the confusion matrix using scikit-learn's plot_confusion_matrix\n",
        "    cm = skplt.metrics.plot_confusion_matrix(true_labels, predicted_labels, figsize=(8, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "e7d73f69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "e7d73f69",
        "outputId": "c95192f0-503c-4631-d1cc-e43cb729a0ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Call the create_confusion_matrix function on your test_loader\n",
        "confusion_matrix = create_confusion_matrix(rnn_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Most common mistakes made by the model\n"
      ],
      "metadata": {
        "id": "q_3mVH7KGNDl"
      },
      "id": "q_3mVH7KGNDl"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}